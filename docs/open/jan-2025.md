---
title: Elf-Disclosure / Jan 2025
description: January was "move-slow-and-fix-stuff", after the disruption of the holiday period, with a focus on expandability and setting ourselves up for more growth. Here some geeky stats, a retrospective, and a look ahead for ElfHosted from Jan 2025
---

# "Elf-Disclosure" for Jan 2025

January was a quiet "public-facing" month, as our various team members and developers were either focusing on holidays, or focusing on in-progress projects. We've quietly added a few new apps / providers to our stack, giving them time to "smoke test" before publically announcing them.

To get us started, here are some geeky stats for Jan 2024, followed by a summary of some of the user-facing changes announced this month in the [blog](https://store.elfhosted.com/blog/)...

## Stats


=== ":seedling: Growth"

    :material-target: Focus            | :material-calendar: Nov 2024 | :material-calendar: Dec 2024 | :material-calendar: Jan 2025
    -----------------------------------|------------------------------|------------------------------|-----------------------------
    :simple-discord: [Discord][discord] members | 2219 | 2328 | 2427
    :simple-youtube: [YouTube](https://www.youtube.com/@elfhostme) subscribers | 579 | 618 | 654
    :simple-tiktok: [TikTok](https://www.tiktok.com/@elfhostme) followers | 28 | 28 | 28
    :simple-x: [X](https://x.com/elfhosted) followers | 88 | 90 | 93

=== ":material-cpu-64-bit: CPU"

    The stats below illustrate CPU cores used (*not percentage*). These stats only cover the DE cluster at present, we're working on cross-cluster metrics aggregation to make this data more useful.

    Tenant CPU load on average is the same as th previous month, but since the graphs now (more usefully) relect 24h of time, it's harder to see minor variations in usage over time.

    ![CPU stats for Dec 2024](/images/reports/2025-01/cluster-cpu-utilization.png)

    ??? "kubectl top nodes"
        ```
        NAME       CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%
        fairy01    3253m        20%    48989Mi         38%
        fairy02    2219m        13%    38351Mi         29%
        fairy03    3600m        22%    35117Mi         27%
        gretel01   1976m        16%    31328Mi         48%
        gretel02   882m         7%     20904Mi         32%
        gretel07   1617m        10%    27626Mi         21%
        gretel08   2241m        14%    41597Mi         32%
        gretel09   1145m        7%     28556Mi         22%
        gretel10   1587m        9%     27677Mi         21%
        gretel11   5257m        32%    40538Mi         31%
        gretel13   681m         4%     64061Mi         49%
        gretel14   944m         5%     26839Mi         20%
        gretel15   1624m        10%    35381Mi         27%
        gretel16   1876m        11%    29543Mi         22%
        gretel17   2683m        16%    40151Mi         31%
        gretel19   1813m        11%    25495Mi         19%
        gretel20   1739m        10%    39069Mi         30%
        gretel22   756m         4%     20475Mi         15%
        gretel23   791m         4%     28535Mi         22%
        gretel26   1452m        9%     24623Mi         19%
        gretel27   1378m        8%     19278Mi         14%
        gretel30   6652m        41%    31794Mi         49%
        gretel31   2038m        12%    82366Mi         63%
        gretel33   2047m        12%    30128Mi         46%
        gretel37   3329m        20%    27933Mi         21%
        hansel01   3332m        27%    49937Mi         77%
        hansel02   2432m        20%    43139Mi         67%
        hansel03   1523m        19%    32627Mi         50%
        hansel13   2077m        25%    45012Mi         70%
        hansel14   3078m        25%    43553Mi         67%
        hansel15   1652m        13%    46544Mi         72%
        hansel16   2741m        22%    42101Mi         65%
        hansel17   1620m        13%    30437Mi         47%
        hansel18   2203m        18%    40614Mi         63%
        hansel19   6146m        51%    48192Mi         75%
        hansel20   1712m        14%    25911Mi         40%
        ```

    Last month (*Dec*)'s for comparison:

    ![CPU stats for Dec 2024](/images/reports/2024-12/cluster-cpu-utilization.png)

    ??? "kubectl top nodes"
        ```
        NAME       CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%
        fairy01    2937m        18%    76426Mi         59%
        fairy02    1869m        11%    55905Mi         43%
        fairy03    701m         4%     79816Mi         62%
        gretel07   1011m        6%     44513Mi         34%
        gretel08   3809m        23%    56575Mi         43%
        gretel09   2334m        14%    52190Mi         40%
        gretel10   605m         3%     37128Mi         28%
        gretel11   2564m        16%    51529Mi         40%
        gretel13   693m         4%     86985Mi         67%
        gretel14   1566m        9%     47162Mi         36%
        gretel15   1870m        11%    45069Mi         35%
        gretel16   2009m        12%    42307Mi         32%
        gretel17   2758m        17%    51826Mi         40%
        gretel19   613m         3%     42791Mi         33%
        gretel20   2339m        14%    46208Mi         35%
        gretel22   654m         4%     39190Mi         30%
        gretel23   2001m        12%    54414Mi         42%
        gretel24   1264m        7%     26617Mi         20%
        gretel25   541m         3%     43809Mi         34%
        gretel26   914m         5%     41056Mi         31%
        gretel27   3908m        24%    38143Mi         29%
        gretel29   1371m        8%     51807Mi         40%
        gretel30   623m         3%     18808Mi         29%
        gretel31   3176m        19%    54015Mi         41%
        gretel33   841m         5%     28607Mi         44%
        gretel37   3779m        23%    63097Mi         49%
        hansel01   3718m        30%    50790Mi         79%
        hansel02   558m         4%     27102Mi         42%
        hansel03   1065m        13%    23775Mi         37%
        hansel13   730m         9%     20304Mi         31%
        hansel14   3016m        25%    49720Mi         77%
        hansel15   3220m        26%    52838Mi         82%
        hansel16   1362m        11%    32593Mi         50%
        hansel17   674m         5%     26916Mi         41%
        hansel18   566m         4%     21870Mi         34%
        hansel19   2093m        17%    53533Mi         83%
        hansel20   1968m        16%    56627Mi         88%
        ```

=== ":material-memory: RAM"

    This graph represents memory usage across the entire (DE) cluster. Tenant memory is relatively stable and consistent with the previous month.

    Other high consumers of RAM:

    * **csi-rclone**: used for mounting all rclone-compatible storage mounts, primarily RealDebrid libraries
    * **kube-system**: the Kubernetes control plane, including the cilium agents which manage the networking / policy enforcement (*currently 11K flows/s across 30 nodes*)
    * **traefik**: all inbound access to the cluster / services
    * **[mediafusion][mediafusion]**: an excellent (*but RAM-hungry!*) [Stremio addon](/stremio-addons/)

    ![Memory stats for Jan 2025](/images/reports/2025-01/cluster-memory-utilization.png)

    ??? "kubectl top nodes"
        ```
        NAME       CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%
        fairy01    3253m        20%    48989Mi         38%
        fairy02    2219m        13%    38351Mi         29%
        fairy03    3600m        22%    35117Mi         27%
        gretel01   1976m        16%    31328Mi         48%
        gretel02   882m         7%     20904Mi         32%
        gretel07   1617m        10%    27626Mi         21%
        gretel08   2241m        14%    41597Mi         32%
        gretel09   1145m        7%     28556Mi         22%
        gretel10   1587m        9%     27677Mi         21%
        gretel11   5257m        32%    40538Mi         31%
        gretel13   681m         4%     64061Mi         49%
        gretel14   944m         5%     26839Mi         20%
        gretel15   1624m        10%    35381Mi         27%
        gretel16   1876m        11%    29543Mi         22%
        gretel17   2683m        16%    40151Mi         31%
        gretel19   1813m        11%    25495Mi         19%
        gretel20   1739m        10%    39069Mi         30%
        gretel22   756m         4%     20475Mi         15%
        gretel23   791m         4%     28535Mi         22%
        gretel26   1452m        9%     24623Mi         19%
        gretel27   1378m        8%     19278Mi         14%
        gretel30   6652m        41%    31794Mi         49%
        gretel31   2038m        12%    82366Mi         63%
        gretel33   2047m        12%    30128Mi         46%
        gretel37   3329m        20%    27933Mi         21%
        hansel01   3332m        27%    49937Mi         77%
        hansel02   2432m        20%    43139Mi         67%
        hansel03   1523m        19%    32627Mi         50%
        hansel13   2077m        25%    45012Mi         70%
        hansel14   3078m        25%    43553Mi         67%
        hansel15   1652m        13%    46544Mi         72%
        hansel16   2741m        22%    42101Mi         65%
        hansel17   1620m        13%    30437Mi         47%
        hansel18   2203m        18%    40614Mi         63%
        hansel19   6146m        51%    48192Mi         75%
        hansel20   1712m        14%    25911Mi         40%
        ```

    Last month (*Dec 2024*)'s for comparison:

    ![Memory stats for Dec 2024](/images/reports/2024-12/cluster-memory-utilization.png)

    ??? "kubectl top nodes"
        ```
        NAME       CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%
        fairy01    2937m        18%    76426Mi         59%
        fairy02    1869m        11%    55905Mi         43%
        fairy03    701m         4%     79816Mi         62%
        gretel07   1011m        6%     44513Mi         34%
        gretel08   3809m        23%    56575Mi         43%
        gretel09   2334m        14%    52190Mi         40%
        gretel10   605m         3%     37128Mi         28%
        gretel11   2564m        16%    51529Mi         40%
        gretel13   693m         4%     86985Mi         67%
        gretel14   1566m        9%     47162Mi         36%
        gretel15   1870m        11%    45069Mi         35%
        gretel16   2009m        12%    42307Mi         32%
        gretel17   2758m        17%    51826Mi         40%
        gretel19   613m         3%     42791Mi         33%
        gretel20   2339m        14%    46208Mi         35%
        gretel22   654m         4%     39190Mi         30%
        gretel23   2001m        12%    54414Mi         42%
        gretel24   1264m        7%     26617Mi         20%
        gretel25   541m         3%     43809Mi         34%
        gretel26   914m         5%     41056Mi         31%
        gretel27   3908m        24%    38143Mi         29%
        gretel29   1371m        8%     51807Mi         40%
        gretel30   623m         3%     18808Mi         29%
        gretel31   3176m        19%    54015Mi         41%
        gretel33   841m         5%     28607Mi         44%
        gretel37   3779m        23%    63097Mi         49%
        hansel01   3718m        30%    50790Mi         79%
        hansel02   558m         4%     27102Mi         42%
        hansel03   1065m        13%    23775Mi         37%
        hansel13   730m         9%     20304Mi         31%
        hansel14   3016m        25%    49720Mi         77%
        hansel15   3220m        26%    52838Mi         82%
        hansel16   1362m        11%    32593Mi         50%
        hansel17   674m         5%     26916Mi         41%
        hansel18   566m         4%     21870Mi         34%
        hansel19   2093m        17%    53533Mi         83%
        hansel20   1968m        16%    56627Mi         88%
        ```

=== ":material-server-network: Network"

    Last month's spikes on the contended nodes (*hansels*) turned out to be related to in-cluster backups, rather than tenant-driven load, and this misconfiguration was resolved. Hansel and Gretel traffic patterns are now more aligned to what you'd expect, comparing December to November:
    
    !!! tip "Why Hansel & Gretel?"
        Bundles are datacenter-agnostic, but nodes are specific to each datacenter, and we needed a way to differentiate US nodes from DE nodes. The fairy tale of [Hansel and Gretel](https://en.wikipedia.org/wiki/Hansel_and_Gretel) originates in Germany :flag_de:

    ![Network traffic for Jan 2025 (*hansels*)](/images/reports/2025-01/cluster-network-utilization-hansels.png)
    
    ![Network traffic for Jan 2025 (*gretels)](/images/reports/2025-01/cluster-network-utilization-gretels.png)

    Last month (*Dec 2024*)'s for comparison:

    ![Network traffic for Dec 2024 (*hansels*)](/images/reports/2024-12/cluster-network-utilization-hansels.png)

    ![Network traffic for Dec 2024 (*gretels)](/images/reports/2024-12/cluster-network-utilization-gretels.png)

## Retrospective

January saw changes in debrid-land, with TorBox pivoting away from Plex users to becoming more of a Stremio-only debrid provider, Riven and Comet slowing/stalling their development, and a new addon ([AIOStreams][aiostreams]) and infinite-library-building app ([cli_debrid][cli-debrid]) being released.

### Mooar apps

The following apps made their debut on ElfHosted during Jan 2024:

#### AIOStreams

[AIOStreams][aiostreams] is a clever new Stremio addon by Viren, author of [one of the most popular guides](https://www.reddit.com/r/StremioAddons/comments/1d42tbq/stremio_the_only_guide_youll_ever_need/) linked to r/StremioAddons.

AIOStreams combines the search results from **other** addons, sorting / filtering them nicely and presenting them to you in one of several beautiful, parsable formats.

Two "killer features" for AIOStreams are:

1. The inclusion of torrentio results (*more on that below*)
2. The support of MediaFlow Proxy, allowing any results from **any** addon to be proxy-streamed through your MediaFlow Proxy instance (*avoiding RD IP bans and the like*)

A few days after an [ElfHosted-sponsored public AIOStreams instance](https://aiostreams.elfhosted.com) was deployed, torrentio started blocking all VPS / server ranges entirely. It may have been co-incidental timing, but the change made it clear that torrentio doesn't **want** automated scraping from VPS/server ranges (*quite reasonably, since one VPS can probably generate 1000x the load that an average Stremio user can*).

As a result, we disabled torrentio scraping on the public AIOStreams instance, but continue to support it via private instances, on the basis that there is user accountability in the case of abuse.

There's a dedicated [#elf-aiostreams](https://discord.com/channels/396055506072109067/1329435155407831070) channel in Discord to discuss the addon, and for direct-to-developer interaction.

#### CWA Automated Book Downloader

[Calibre Web Automated Downloader][cwa-book-downloader] is an app intended for use alongside [Calibre-Web Automated][calibre-web], whose role it is to search and download ebooks from online web sources. It augments the existing [OpenBooks][openbooks] app, which does a similar thing, from IRC sources.

More details in [this blog post](https://store.elfhosted.com/blog/2025/01/02/introducing-calibre-web-automated-book-downloader/)

#### CLI Debrid

cli_debrid is a new project inspired by the original plex_debrid, and is currently very actively developed by [godver3](https://github.com/godver3/cli_debrid).

Ironically, the first thing you'll notice about cli_debrid is its web UI. The UI handles all the settings / config / scraping options (*farewell, annoying plex_debrid menu structure!*), and the app itself still runs in a CLI within the UI.

We have cli_debrid versions of all of our bundles, and a dedicated [#elf-cli-debrid](https://discord.com/channels/396055506072109067/1326389922998915154) channel in Discord for your direct-to-developer access.

godver3 is also an Elf-illiated developer (*see more below*), so 33% of your cli_debrid subscription funds his ongoing development!

#### CineSync

A challenge with offering non-zurg-based Debrid storage mounts has been how to separate movies from TV shows, so that Plex has different libraries to scan for different types of content. 

We have bespoke options for various debrid providers (*Zurg makes this easy enough for RealDebrid, DebriDav does the same with the Aaars for Premiumize, and DavDebrid for DebridLink*), but running multiple providers at the same time can get messy, and AllDebrid doesn't work for us with DavDebrid due to API restrictions.

[CineSync][cinesync] is a standalone project which will look at **multiple** source locations (*think RealDebrid combined with AllDebrid!*), sort the contents based on regexes and TMDB lookups, and create a separate set of structured symlinks sorted by content type, resolution, etc. These symlinks are maintained by CineSync (*so they're deleted if the source is deleted*), and CineSync is able to (*with a Plex token*) tell Plex to refresh a library when new content is added.

A few users have been trialling CineSync for the last month or so - it can be too slow on large libraries (development is ongoing in that area), but it's also super-handy for the Zurgling design, when users want a better-sorted view of their content than the mess of inconsistently-named folders that Zurg reflects from RD.

#### DebriDav

DebriDav is sort of like a combination of Zurg and RDTClient. It both simulates a qBittorrent API (*for the Aars to add downloads*), and a WebDAV server (*for rclone mounts*), and is an ingenious workaround for the 1TB "cloud storage" limit on Premiumize.

DebriDav works **not** by adding cached items to your library (*which would hit the 1TB limit*), but simply storing its own "placeholder" file representing items known to be cached, and serving that via WebDAV *as if it were* the full file.

This fake-file trickery means that (*as with symlinks*), the file the user "sees" can be renamed, moved, etc, but it's only when the file is attempted to be **played**, that the actual content is streamed from Premiumize. Since the file is not actually added to your Premiumize, just played directly from the cache (like when you use Stremio with Premiumize), it doesn't incur cloud-storage costs. Premiumize "fair use" points are still required to stream from the cache.

We have a few enthusiastic users testing the Premiumize implementation, on the understanding that it's new-and-may-break, and a recent release has also enabled **EasyNews** support (*currently entirely undocumented on our end, but hit me up if you'd like to test*). 

Once the existing trials have had a little more time to bed in (*and especially EasyNews users*), we'll do a bigger announcement.

### Torrentio blocks servers

As noted in the AIOStreams introduction above, torrentio no longer permits access from server ranges, presumably to prevent abuse and to reserve their (*freely available*) resources for the widest range of standard Stremio users.

Respecting this position, while the VPNs on our Stremio addons avoid this ban for private instances, we are **not** going to attempt a VPN-based workaround for Plex-library-building apps such as [Prowlarr][prowlarr], [plex_debrid][plex-debrid], etc.

ElfHosted's [super-charged internal Zilean](https://store.elfhosted.com/blog/2024/11/19/project-zycops-is-a-go/) instance, combined with our internal (*un-ratelimted*) MediaFusion access, provide very good coverage of cached content already, and users can add a range of external scrapers and indexers to their tools, without imposing unfairly upon torrentio.

### Stremio Addons SSO

Initially we made Stremio addons fully public (*they need to be public for Stremio to use them, since it doesn't support auth*), but users raised valid concerns about the security of their API credentials when sharing their addon with friends and family.

In early Jan, we added SSO support to the `/configure` pages of the addons, such that in order to **configure** an addon, you'll need to be signed into your ElfHosted account. The addon can be **used** (*and shared*) without SSO though, a compromise between security and practicality.

Additionally, some addons (*[AIOStreams][aiostreams] and [MediaFusion][mediafusion] currently*) support user-managed encryption schemes, so that a shared addon URL doesn't expose any sensitive data.

More details in [this blog post](https://store.elfhosted.com/blog/2025/01/03/stremio-addons-get-fixed-sso/).

### Comet cools

The Comet Stremio Addon has been semi-functional since the debrid providers withdrew their cache endpoint checks in November. With the help of StremThru, we've restored **some** ability to work with RD/AD/DL, but development on the "[rewrite](https://github.com/g0ldyy/comet/pull/234)" branch to properly address this, is currently on hold.

If Comet is working for you currently, then continue to use it, but if you're having issues, we should note that they're unlikely to be fixed in the short term, and we'd suggest transitioning to [MediaFusion][mediafusion], which now also has [Jackett][jackett] support (*for searching your own indexers*), and the ability to proxy-stream using [MediaFlow Proxy][mediaflow-proxy].

Open an [#elf-help][elf-help] ticket if you'd like advice re transitioning.

### TorBox turns

Torbox has [made it clear](https://www.reddit.com/r/TorBoxApp/comments/1hqtxqr/torbox_requested_riven_dev_to_remove_support/) that they're not to be used for "infinite library" setups, to the point that cached items in your library will be removed after 30 days of inactivity, and that efforts to circumvent this expiry are classified as "abuse".

TorBox also requested Riven remove their TorBox integration, since this was observed to be a common vector for automated abuse, so as of the next published release of Riven, TorBox support will be removed (*there are no longer any ElfHosted Riven+TorBox users*).

### Riven recedes

On the heels of the TorBox change, Riven's development team took a 2-month hiatus during Dec/Jan, to rest and recuperate, and many user issues / bugs went unanswered / unfixed, causing some users to question whether Riven was abandoned.

The development team has re-organised and brought on another front-end developer and project-management skills, but has made it clear that Riven is a passion project, to be progressed as and when the developers have the time and the enthusiasm.

For ElfHosted users, this means we can no longer reasonably expect Elf-specific bugfixes / features "at pace", and users who find themselves "stuck" are advised to transition to the classic Aars stack, or try out the new-but-energetically-developed cli_debrid. 

Open an [#elf-help][elf-help] ticket if you'd like advice re transitioning.

### Premiumize performs

Now that we have a workable way to integrate Premiumize as a debrid provider into Plex libraries, without the 1TB cloud-storage limit, we intend to polish up our Premiumize-integrated offering.

We're pursuing a special deal with Premiumize (TBD), but in the short-term, we've been given a collection of 14-day trial vouchers for Premiumize, for Plex users who want to try it out. 

More details will follow once DebriDav settles, and if a special Premiumize deal can be reached, but open an [#elf-help][elf-help] ticket in the meantime to request your Premiumize trial voucher!

### US Cluster speed fixes

Due to the gradual way we grew out the US cluster, we ended up in a situation where our cluster CNI was using VXLAN tunnels between publically addressed nodes (*on different subnets*) to provide our network overlay. While not **wrong**, this is inefficient and hard to debug. 

Additionally, the integration of tailscale on a node level seemed to cause unwanted interaction, "amplifying" tunneled traffic between all the cluster nodes, and effectively creating a hard-to-debug intermittent speed problem which only affected **some** of the users, on **some** of the nodes, **some** of the time.

There are some technical limitations to the hosting configuration which led to this setup, but during a few glowups towards the end of January, we worked around these to get rid of the tunnels (*and the tailscales*), and as a result we now have optimal speeds in the US cluster again.

We've recently been quiet about encouraging migrations from DE to US until the speed issue was resolved, but now that it's been put to bed, we'll be suggesting that US users test their speed at https://speed.elfhosted.com, and migrate their stack if it's significantly to their advantage.

## Coming up

### US East Coast DC

Yes. I know. We talk about this every month. The latest from CrunchBits as of 30 Jan is that they're waiting for **their** provider to make space for new gear, and our order (*placed months ago but not paid yet*) is a priority.

Watch this space (*as usual*).

### Elf-illiate program trial

We have an automated [referral program](https://store.elfhosted.com/pay-it-forward/), making it possible for happy Elfies to "pay it forward" by referring us to friends, and receiving a $10 credit against their account if this referral converts.

During January, we transitioned our (*previously manual and dumb*) developer contributions system to a more advanced "Elf-illiate" program, which allows us to calculate and pay out our participating open-source developers for a portion of subscription fees.

Unlike the referral program, the [affiliate program](https://store.elfhosted.com/affiliate/) requires approval, but pays out directly in cash, as opposed to account credit. The idea is to encourage users with an "audience" (*elf-influencers?*) to spread the word about ElfHosted, in return for a percentage of commission on sales.

We'll cover this in a detailed blog post during February, but if you're interested in helping with an initial trial, start your Elf-illiate application [here](https://store.elfhosted.com/affiliate/).

### Even mooar apps

Apps currently requested can be found (and submitted!) [here](https://github.com/elfhosted/enhancements/issues?q=sort%3Aupdated-desc+is%3Aissue+is%3Aopen)

Notable suggestions:

* [TitleCardMaker](https://titlecardmaker.com/) (*CLI version for now*)

### ElfGuides (ongoing)

We've made videos about how to drive our most popular setups, but given the tools and apps change so fast, the videos very often become out-of-date. Re-recording a video simply to address a change a single tool in a larger workflow can be tedious and time-consuming, so we've been exploring another option.

The "ElfGuides" are a collection of ScribeHow documents, assembled modularly from a collection of "Scribes" (*screenshot-driven guides*), which can be mix/matched up to provide a detailed guide per-stack (*there are more than 30 variations now*!). When a tool in the stack changes, updating the guides is just a matter of updating the individual "module" covering that tool.

If you've been a long-time Elfie, you'll not have seen any guides, but they're emailed to new subscribers as they start their subscription!

The most popular app stacks are covered in the ElfGuides currently, but given the variety / rate of change we face, the effort to maintain these is... ongoing.

### Your ideas?

Got ideas for improvements? Send us an EEP (*ElfHosted Enhancement Proposal*) [here](https://github.com/elfhosted/enhancements/issues/new/choose)!

## How to help

Another effective way to help is to drive traffic / organic discovery, by mentioning ElfHosted in appropriate forums such as Reddit's [r/plex](https://reddit.com/r/plex),  [r/realdebrid](https://reddit.com/r/realdebrid), and [r/StremioAddons](https://reddit.com/r/StremioAddons), which is where much of our target audience is to be found!

## Join us!

!!! tip "Want to get involved?"

    Want to get involved? Join us in [Discord][discord]!

--8<-- "common-links.md"

{% include 'testimonials.md' %}